{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Learning_Competition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wVsDbcavjCKc",
        "IwSiNNMpWS4n",
        "dBg_lCVoVUZj",
        "WLSvsLVpNTJ0",
        "i6Wk6yzBZgQf"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HayaLababidi/indoor-scenes-Recognition/blob/master/Deep_Learning_Competition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqrTPqoAWKll",
        "colab_type": "text"
      },
      "source": [
        "# Get Dataset or only the Saved features in drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yab_vTDURhkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download all files in gdrive folder\n",
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1xAboz-oYGj-KI2DBTdrCA98oi1aEH5lW' in parents\"}).GetList()\n",
        "\n",
        "for f in file_list:\n",
        "  # 3. Create & download by id.\n",
        "  print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "  fname = f['title']\n",
        "  print('downloading to {}'.format(fname))\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2tZsR-rMzdg",
        "colab_type": "text"
      },
      "source": [
        "**Download  Dataset from Kaggle, unrar and read dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kN8hXKELkc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -lha kaggle.json\n",
        "!pip install -q kaggle\n",
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle competitions download -c fcis-cs-deeplearningcompetition"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN2SWfu4SPn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unrar x test.rar\n",
        "!unrar x train.rar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSyABWrSRnhc",
        "colab_type": "text"
      },
      "source": [
        "**Read train data and labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CwvFV5kgoON",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Read train data and labels\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "n_rows = 299\n",
        "n_cols = 299\n",
        "n_training_img = 3138\n",
        "\n",
        "\n",
        "def read_train_images(dir):\n",
        "    images=np.zeros(shape=(n_training_img,n_rows,n_cols,3), dtype= np.float16)\n",
        "    labels=np.zeros(shape=(n_training_img), dtype=np.int8)\n",
        "    String_labels=[]\n",
        "    \n",
        "    i=0\n",
        "    class_label=0\n",
        "    for root, dirs, files in os.walk(dir):\n",
        "        temp_label=''\n",
        "        for name in files:\n",
        "            temp_label=root[6:]\n",
        "            image_file_name=os.path.join(root, name)\n",
        "            img = cv2.imread(image_file_name, cv2.IMREAD_COLOR)\n",
        "            if img is not None:\n",
        "                img = img[:, :, [2, 1, 0]]  # Make it RGB\n",
        "                img = cv2.resize(img, (n_rows, n_cols))\n",
        "                img = 2 * (img / 255.0) - 1.0\n",
        "                images[i]=img\n",
        "                del img\n",
        "                labels[i]=class_label\n",
        "                i=i+1\n",
        "                \n",
        "        if temp_label != '':\n",
        "          print(temp_label)\n",
        "          print(class_label)\n",
        "          class_label=class_label+1\n",
        "          String_labels.append(temp_label)\n",
        "    return images, String_labels, labels\n",
        "images, String_labels, labels = read_train_images('train')\n",
        "\n",
        "#split the data into train and validation sets with default shuffle\n",
        "X_train, X_Val, y_train, y_Val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "#y_train_one_hot = tf.one_hot(y_train,10)\n",
        "#y_Val_one_hot = tf.one_hot(y_Val,10)\n",
        "#del y_train\n",
        "#del y_Val\n",
        " \n",
        "#convert all lists to np arrray \n",
        "X_train = np.asarray(X_train,dtype=np.float16)\n",
        "X_Val = np.asarray(X_Val,dtype=np.float16)\n",
        "y_train = np.asarray(y_train,dtype=np.float16)\n",
        "y_Val = np.asarray(y_Val,dtype=np.float16)\n",
        "String_labels = np.asarray(String_labels)\n",
        "\n",
        "print(X_train.shape, X_Val.shape, y_train.shape, y_Val.shape)\n",
        "\n",
        "#save the np arrays \n",
        "np.save('X_train.npy', X_train)\n",
        "np.save('X_Val.npy', X_Val)\n",
        "np.save('y_train.npy', y_train)\n",
        "np.save('y_Val.npy', y_Val)\n",
        "np.save('String_labels.npy',String_labels)\n",
        "\n",
        "#delete all arrays from memory to avoid crash due lack of memory\n",
        "del images\n",
        "del labels\n",
        "del X_train\n",
        "del X_Val\n",
        "del y_train\n",
        "del y_Val\n",
        "del String_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2KNOEZURsRE",
        "colab_type": "text"
      },
      "source": [
        "**Read test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjjsULCMRsbm",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Read test Data\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot  as plt\n",
        "n_rows = 299\n",
        "n_cols = 299\n",
        "n_testing_img = 772\n",
        "\n",
        "\n",
        "def read_test_images(dir):\n",
        "    images=np.zeros(shape=(n_testing_img,n_rows,n_cols,3), dtype= np.float16)\n",
        "    img_names=[]\n",
        "    i=0\n",
        "    \n",
        "    for img_name in (os.listdir(dir)):\n",
        "        path = os.path.join(dir, img_name)\n",
        "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "        if img is None:\n",
        "            img = plt.imread(path, cv2.IMREAD_COLOR)\n",
        "        if img is not None:\n",
        "            img = img[:, :, [2, 1, 0]]  # Make it RGB\n",
        "            img = cv2.resize(img, (n_rows, n_cols))\n",
        "            img = 2 * (img / 255.0) - 1.0\n",
        "            images[i]=img\n",
        "            img_names.append(img_name)\n",
        "            i=i+1\n",
        "            del img\n",
        "\n",
        "    return images,img_names\n",
        "X_test,img_names = read_test_images('test')\n",
        "\n",
        "print(X_test.shape)\n",
        "img_names = np.asarray(img_names)\n",
        "#save the np arrays \n",
        "np.save('X_test.npy', X_test)\n",
        "np.save('img_names.npy', img_names)\n",
        "\n",
        "#delete all arrays from memory to avoid crash due lack of memory\n",
        "del X_test\n",
        "del img_names\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVsDbcavjCKc",
        "colab_type": "text"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjMAvn4sEFJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from scipy import ndarray\n",
        "import skimage as sk\n",
        "from skimage import transform\n",
        "from skimage import util\n",
        "from skimage.color import rgb2gray\n",
        "from skimage import exposure\n",
        "from scipy import ndimage\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "\n",
        "def clipped_zoom(img):\n",
        "    zoom_factor=1.25\n",
        "    h, w = img.shape[:2]\n",
        "    zoom_tuple = (zoom_factor,zoom_factor,1)#for h and width\n",
        "    # Bounding box of the zoomed-in region within the input array\n",
        "    zh = int(np.round(h / zoom_factor))\n",
        "    zw = int(np.round(w / zoom_factor))\n",
        "    top = (h - zh) // 2\n",
        "    left = (w - zw) // 2\n",
        "    return zoom(img[top:top+zh, left:left+zw], zoom_tuple)\n",
        "     \n",
        "\n",
        "def random_rotation(image_array: ndarray):\n",
        "    # pick a random degree of rotation between 25% on the left and 25% on the right\n",
        "    random_degree = random.uniform(-25, 25)\n",
        "    return sk.transform.rotate(image_array, random_degree)\n",
        "\n",
        "def random_noise(image_array: ndarray):\n",
        "    # add random noise to the image\n",
        "    return sk.util.random_noise(image_array)\n",
        "\n",
        "def horizontal_flip(image_array: ndarray):\n",
        "    # horizontal flip doesn't need skimage, it's easy as flipping the image array of pixels !\n",
        "    return image_array[:, ::-1]\n",
        "\n",
        "def vertical_flip(image_array: ndarray):\n",
        "    # horizontal flip doesn't need skimage, it's easy as flipping the image array of pixels !\n",
        "    return image_array[::-1, :]\n",
        "\n",
        "def rescale(image_array: ndarray):############################# make it zoom\n",
        "    return sk.transform.rescale(image_array,1.0 / 2.0)\n",
        "\n",
        "def color2gray(image_array: ndarray):\n",
        "    return rgb2gray(image_array)\n",
        "\n",
        "def rotate90(image_array: ndarray):\n",
        "    return np.rot90(image_array)\n",
        "\n",
        "def Blurimage(image_array: ndarray):\n",
        "    return ndimage.uniform_filter(image_array, size=(5, 3, 1))\n",
        "\n",
        "image_to_transform = sk.io.imread('train/greenhouse/04_06Greenhouse.jpg')\n",
        "img=random_noise(image_to_transform)\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "img=clipped_zoom(img)\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lz4G3EOjHd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from scipy import ndarray\n",
        "import skimage as sk\n",
        "from skimage import transform\n",
        "from skimage import util\n",
        "from skimage.color import rgb2gray\n",
        "from skimage import exposure\n",
        "from scipy import ndimage\n",
        "import os\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "\n",
        "\n",
        "# our folder path containing some images\n",
        "folder_path = 'train'\n",
        "# our folder path containing augmented images\n",
        "folder_augmentation = 'augmentedImages'\n",
        "\n",
        "def clipped_zoom(image_array: ndarray):\n",
        "    zoom_factor=random.uniform(1.5, 4)\n",
        "    h, w = image_array.shape[:2]\n",
        "    zoom_tuple = (zoom_factor,zoom_factor,1)#for h and width\n",
        "    # Bounding box of the zoomed-in region within the input array\n",
        "    zh = int(np.round(h / zoom_factor))\n",
        "    zw = int(np.round(w / zoom_factor))\n",
        "    top = (h - zh) // 2\n",
        "    left = (w - zw) // 2\n",
        "    return zoom(image_array[top:top+zh, left:left+zw], zoom_tuple)\n",
        "\n",
        "def random_rotation(image_array: ndarray):\n",
        "    # pick a random degree of rotation between 25% on the left and 25% on the right\n",
        "    random_degree = random.uniform(-25, 25)\n",
        "    return clipped_zoom(sk.transform.rotate(image_array, random_degree))\n",
        "\n",
        "def random_noise(image_array: ndarray):\n",
        "    # add random noise to the image\n",
        "    return sk.util.random_noise(image_array)\n",
        "\n",
        "def horizontal_flip(image_array: ndarray):\n",
        "    # horizontal flip doesn't need skimage, it's easy as flipping the image array of pixels !\n",
        "    return image_array[:, ::-1]\n",
        "\n",
        "def vertical_flip(image_array: ndarray):\n",
        "    # horizontal flip doesn't need skimage, it's easy as flipping the image array of pixels !\n",
        "    return image_array[::-1, :]\n",
        "\n",
        "def rescale(image_array: ndarray):\n",
        "    return sk.transform.rescale(image_array,1.0 / 2.0)\n",
        "\n",
        "def color2gray(image_array: ndarray):\n",
        "    return rgb2gray(image_array)\n",
        "\n",
        "def rotate90(image_array: ndarray):\n",
        "    return np.rot90(image_array)\n",
        "\n",
        "def Rescaleintensity(image_array: ndarray):\n",
        "    v_min, v_max = np.percentile(image_array, (0.2, 99.8))\n",
        "    return exposure.rescale_intensity(image_array, in_range=(v_min, v_max))\n",
        "\n",
        "def Blurimage(image_array: ndarray):\n",
        "    return ndimage.uniform_filter(image_array, size=(3, 3, 1))\n",
        "\n",
        "\n",
        "\n",
        "def DataAugmentation(Total_num_files_desired):\n",
        "    all_directories = [name for name in os.listdir(folder_path)\\\n",
        "               if os.path.isdir(os.path.join(folder_path, name))]\n",
        "    #all_directories=['bakery','bedroom','gym','kitchen']\n",
        "    for classFolder in all_directories:\n",
        "        # loop on all files of the folder and build a list of files paths\n",
        "        images = [os.path.join(os.path.join(folder_path,classFolder), f) for f in os.listdir(os.path.join(folder_path,classFolder)) if os.path.isfile(os.path.join(os.path.join(folder_path,classFolder), f))]\n",
        "        \n",
        "        # the number of images to generate\n",
        "        num_files_desired = Total_num_files_desired-len(images)\n",
        "        print(classFolder,num_files_desired)\n",
        "        transformed_total_images=[]\n",
        "        for img in images:\n",
        "            try: \n",
        "                # random image from the folder\n",
        "                image_path = img\n",
        "                # read image as an two dimensional array of pixels\n",
        "                image_to_transform = sk.io.imread(image_path)\n",
        "\n",
        "                # dictionary of the transformations functions we defined earlier\n",
        "                available_transformations = {\n",
        "                    'random_rotation': random_rotation,\n",
        "                    #'random_noise': random_noise,\n",
        "                    'horizontal_flip': horizontal_flip,\n",
        "                    'clipped_zoom': clipped_zoom,\n",
        "                    #'vertical_flip': vertical_flip,\n",
        "                    #'rescale': rescale,\n",
        "                    #'color2gray': color2gray,\n",
        "                    #'rotate90': rotate90,\n",
        "                    #'Rescale intensity': Rescaleintensity,\n",
        "                    #'Blur image': Blurimage\n",
        "                }\n",
        "\n",
        "                # random num of transformations to apply\n",
        "                #num_transformations_to_apply = random.randint(1, len(available_transformations))\n",
        "\n",
        "                num_transformations = 0\n",
        "                transformed_image = None\n",
        "                # can make 4 transformation in single image\n",
        "                #while num_transformations < 3:\n",
        "                for key in available_transformations:\n",
        "                    # choose a random transformation to apply for a single image\n",
        "                    #key = random.choice(list(available_transformations))\n",
        "                    transformed_image = available_transformations[key](image_to_transform)\n",
        "                    #image_to_transform = transformed_image\n",
        "                    transformed_total_images.append(image_to_transform)\n",
        "                    num_transformations += 1\n",
        "                    if num_files_desired < 100 and num_transformations == 1:\n",
        "                        #print(key)\n",
        "                        break\n",
        "                # define a name for our new file\n",
        "            except:\n",
        "               pass\n",
        "        \n",
        "        num_generated_files = 0\n",
        "        random.shuffle(transformed_total_images)\n",
        "        while num_generated_files < num_files_desired and num_generated_files < len(transformed_total_images):\n",
        "            try:    \n",
        "                new_file_path = '%s/augmented_image_%s.jpg' % (os.path.join(folder_augmentation,classFolder), num_generated_files)\n",
        "\n",
        "                if not os.path.exists(os.path.join(folder_augmentation,classFolder)):\n",
        "                    os.makedirs(os.path.join(folder_augmentation,classFolder))\n",
        "\n",
        "                # write image to the disk\n",
        "                transformed_image = transformed_total_images[num_generated_files]\n",
        "                sk.io.imsave(new_file_path, transformed_image)\n",
        "            except:\n",
        "              pass\n",
        "            num_generated_files = num_generated_files + 1\n",
        "        print(num_generated_files)\n",
        "\n",
        "Total_num_files_desired = 500\n",
        "\n",
        "DataAugmentation(Total_num_files_desired)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SypgTRz_jvEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "\n",
        "!zip -r augmentedImages5.zip augmentedImages\n",
        "\n",
        "#!unzip augmentedImages4.zip\n",
        "\n",
        "#shutil.rmtree('augmentedImages/gym')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCx8F84kz8FQ",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "74520ba0-5b66-4e01-b03d-8ec72b98721e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "#@title Read Augmented data and labels\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "n_rows = 299\n",
        "n_cols = 299\n",
        "n_aug_img = 1756\n",
        "\n",
        "train_lebels_dictionary={\n",
        "'airport_inside':\t2,\n",
        "'bakery':\t6,\n",
        "'bedroom':\t5,\n",
        "'greenhouse':\t8,\n",
        "'gym':\t0,\n",
        "'kitchen':\t7,\n",
        "'operating_room':\t9,\n",
        "'poolinside':\t3,\n",
        "'restaurant':\t1,\n",
        "'toystore':\t4}\n",
        "\n",
        "def read_train_images(dir):\n",
        "    images=np.zeros(shape=(n_aug_img,n_rows,n_cols,3), dtype= np.float16)\n",
        "    labels=[]\n",
        "    String_labels=[]\n",
        "    \n",
        "    i=0\n",
        "    #class_label=0\n",
        "    for root, dirs, files in os.walk(dir):\n",
        "        temp_label=''\n",
        "        for name in files:\n",
        "            temp_label=root[16:]\n",
        "            image_file_name=os.path.join(root, name)\n",
        "            img = cv2.imread(image_file_name, cv2.IMREAD_COLOR)\n",
        "            if img is not None:\n",
        "                img = img[:, :, [2, 1, 0]]  # Make it RGB\n",
        "                img = cv2.resize(img, (n_rows, n_cols))\n",
        "                img = 2 * (img / 255.0) - 1.0\n",
        "                images[i]=img\n",
        "                del img\n",
        "                labels.append(train_lebels_dictionary[temp_label])\n",
        "                i=i+1\n",
        "                \n",
        "        if temp_label != '':\n",
        "          print(temp_label)\n",
        "          #print(class_label)\n",
        "          #class_label=class_label+1\n",
        "          String_labels.append(temp_label)\n",
        "    print(i)\n",
        "    return images, String_labels, labels\n",
        "images, String_labels, labels = read_train_images('augmentedImages')\n",
        "\n",
        "\n",
        "#convert all lists to np arrray \n",
        "X_aug = np.asarray(images,dtype=np.float16)\n",
        "y_aug = np.asarray(labels)\n",
        "String_labels_aug = np.asarray(String_labels)\n",
        "\n",
        "\n",
        "\n",
        "#save the np arrays \n",
        "np.save('X_aug.npy', X_aug)\n",
        "np.save('y_aug.npy', y_aug)\n",
        "np.save('String_labels_aug.npy',String_labels_aug)\n",
        "\n",
        "#delete all arrays from memory to avoid crash due lack of memory\n",
        "print(X_aug.shape)\n",
        "print(y_aug.shape)\n",
        "print(images.shape)\n",
        "print(len(labels))\n",
        "del images\n",
        "del labels\n",
        "del y_aug\n",
        "del X_aug\n",
        "del String_labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "airport_inside\n",
            "poolinside\n",
            "operating_room\n",
            "toystore\n",
            "greenhouse\n",
            "restaurant\n",
            "gym\n",
            "bakery\n",
            "1756\n",
            "(1756, 299, 299, 3)\n",
            "(1756,)\n",
            "(1756, 299, 299, 3)\n",
            "1756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwSiNNMpWS4n",
        "colab_type": "text"
      },
      "source": [
        "# Model & Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4-3sIo_luAt",
        "colab_type": "text"
      },
      "source": [
        "**Dowlnoad Pretrained Model checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EZyeQeqWVuN",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "e14a32b6-c859-42ff-b1db-567751833fd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title Download ResNet Model checkpoint\n",
        "import requests\n",
        "\n",
        "url = 'http://download.tensorflow.org/models/inception_resnet_v2_2016_08_30.tar.gz'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('inception_resnet_v2_2016_08_30.tar.gz', 'wb').write(r.content)\n",
        "!tar -xvf inception_resnet_v2_2016_08_30.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inception_resnet_v2_2016_08_30.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQH865ZSlw_z",
        "colab_type": "code",
        "outputId": "af1ab0ae-3af8-4546-faa2-de907d7321b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "#to be able to call the function that define the shape of the model \n",
        "exec(compile(open(\"inception_resnet_v2.py\", \"rb\").read(), \"inception_resnet_v2.py\", 'exec'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zsWnLBND_No",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Restore ResNet Model\n",
        "# ------------------------------------------------------------------------------\n",
        "# Imports\n",
        "# ------------------------------------------------------------------------------\n",
        "import tensorflow as tf\n",
        "import inception_resnet_v2 as incep_v2\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm # Or from tqdm import tqdm if not jupyter notebook\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "n_rows = 299\n",
        "n_cols = 299\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Declarations\n",
        "# ------------------------------------------------------------------------------\n",
        "def define_model(model, is_training):\n",
        "    model.Image = tf.placeholder(tf.float32, shape=[None, n_rows, n_cols, 3])\n",
        "    with incep_v2.slim.arg_scope(incep_v2.inception_resnet_v2_arg_scope()):\n",
        "        model.logits, model.end_points = incep_v2.inception_resnet_v2_base(model.Image)\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "class Model_Class:\n",
        "    def __init__(self, is_training):\n",
        "        define_model(self, is_training=is_training)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Create Model\n",
        "# ------------------------------------------------------------------------------\n",
        "model = Model_Class(False)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Load the weights and Run the classifier\n",
        "# ------------------------------------------------------------------------------\n",
        "model.saver = tf.train.Saver()\n",
        "model.saver.restore(sess, \"inception_resnet_v2_2016_08_30.ckpt\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I10zkIzxKYrn",
        "colab_type": "text"
      },
      "source": [
        "**Feature Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUpUuuW410yK",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Feature Extraction Train Data\n",
        "import numpy as np\n",
        "import tflearn\n",
        "\n",
        "start = 100\n",
        "end = 2500\n",
        "step = 100\n",
        "#(2510, 299, 299, 3)\n",
        "X_train = np.load('X_train.npy')\n",
        "#can't do it at once Memory Crash\n",
        "X_train_features = sess.run(model.logits, feed_dict={model.Image:X_train[0:start]})\n",
        "\n",
        "for i in range(start,end,step):\n",
        "    print(i,i+step)\n",
        "    X_train_features_temp = sess.run(model.logits, feed_dict={model.Image:X_train[i:i+step]})\n",
        "    X_train_features = tf.concat([X_train_features,X_train_features_temp],0)\n",
        "X_train_features_temp = sess.run(model.logits, feed_dict={model.Image:X_train[end:]})\n",
        "X_train_features = tf.concat([X_train_features,X_train_features_temp],0)\n",
        "X_train_features.shape\n",
        "del X_train\n",
        "\n",
        "sess.run(X_train_features)\n",
        "X_train_features_np=X_train_features.eval(session=sess)\n",
        "print(X_train_features_np.shape)\n",
        "np.save('X_train_features.npy',X_train_features_np)\n",
        "del X_train_features\n",
        "del X_train_features_np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKOJ0Isy9kdP",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Feature Extraction Validation Data\n",
        "import numpy as np\n",
        "import tflearn\n",
        "\n",
        "start = 100\n",
        "end = 600\n",
        "step = 100\n",
        "#(628, 299, 299, 3)\n",
        "X_Val = np.load('X_Val.npy')\n",
        "X_Val_features = sess.run(model.logits, feed_dict={model.Image:X_Val[0:start]})\n",
        "\n",
        "for i in range(start,end,step):\n",
        "    print(i,i+step)\n",
        "    X_Val_features_temp = sess.run(model.logits, feed_dict={model.Image:X_Val[i:i+step]})\n",
        "    X_Val_features = tf.concat([X_Val_features,X_Val_features_temp],0)\n",
        "X_Val_features_temp = sess.run(model.logits, feed_dict={model.Image:X_Val[end:]})\n",
        "X_Val_features = tf.concat([X_Val_features,X_Val_features_temp],0)\n",
        "X_Val_features.shape\n",
        "del X_Val\n",
        "\n",
        "sess.run(X_Val_features)\n",
        "X_Val_features_np=X_Val_features.eval(session=sess)\n",
        "print(X_Val_features_np.shape)\n",
        "np.save('X_Val_features.npy',X_Val_features_np)\n",
        "del X_Val_features\n",
        "del X_Val_features_np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z60AH01n_C1j",
        "colab_type": "code",
        "outputId": "264a86dc-4387-4ff7-ec81-35948ed29448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_aug = np.load('X_aug.npy')\n",
        "print(X_aug.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1756, 299, 299, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPO96vxBJ840",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Feature Extraction Augmentation Data\n",
        "import numpy as np\n",
        "import tflearn\n",
        "\n",
        "start = 100\n",
        "end = 1700\n",
        "step = 100\n",
        "#(1980, 299, 299, 3)\n",
        "#X_aug = np.load('X_aug.npy')\n",
        "#can't do it at once Memory Crash\n",
        "X_aug_features = sess.run(model.logits, feed_dict={model.Image:X_aug[0:start]})\n",
        "\n",
        "for i in range(start,end,step):\n",
        "    print(i,i+step)\n",
        "    X_aug_features_temp = sess.run(model.logits, feed_dict={model.Image:X_aug[i:i+step]})\n",
        "    X_aug_features = tf.concat([X_aug_features,X_aug_features_temp],0)\n",
        "X_aug_features_temp = sess.run(model.logits, feed_dict={model.Image:X_aug[end:]})\n",
        "X_aug_features = tf.concat([X_aug_features,X_aug_features_temp],0)\n",
        "X_aug_features.shape\n",
        "del X_aug\n",
        "\n",
        "sess.run(X_aug_features)\n",
        "X_aug_features_np=X_aug_features.eval(session=sess)\n",
        "print(X_aug_features_np.shape)\n",
        "np.save('X_aug_features.npy',X_aug_features_np)\n",
        "del X_aug_features\n",
        "del X_aug_features_np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya1vR4XA6AH3",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Feature Extraction Test Data\n",
        "import numpy as np\n",
        "import tflearn\n",
        "\n",
        "start = 100\n",
        "end = 700\n",
        "step = 100\n",
        "#(772, 299, 299, 3)\n",
        "X_test = np.load('X_test.npy')\n",
        "X_test_features = sess.run(model.logits, feed_dict={model.Image:X_test[0:start]})\n",
        "\n",
        "for i in range(start,end,step):\n",
        "    print(i,i+step)\n",
        "    X_test_features_temp = sess.run(model.logits, feed_dict={model.Image:X_test[i:i+step]})\n",
        "    X_test_features = tf.concat([X_test_features,X_test_features_temp],0)\n",
        "X_test_features_temp = sess.run(model.logits, feed_dict={model.Image:X_test[end:]})\n",
        "X_test_features = tf.concat([X_test_features,X_test_features_temp],0)\n",
        "X_test_features.shape\n",
        "del X_test\n",
        "\n",
        "sess.run(X_test_features)\n",
        "X_test_features_np=X_test_features.eval(session=sess)\n",
        "print(X_test_features_np.shape)\n",
        "np.save('X_test_features.npy',X_test_features_np)\n",
        "del X_test_features\n",
        "del X_test_features_np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJRaZfq_Kt29",
        "colab_type": "text"
      },
      "source": [
        "**Upload Extraced features and labels to drive , Not to do feature extration every time**\n",
        "\n",
        "Executed only when we do feature extration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9aV-JZuQ36o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Upload features & labels to drive { display-mode: \"code\" }\n",
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "fid = '1xAboz-oYGj-KI2DBTdrCA98oi1aEH5lW'\n",
        "'''f = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": fid}]})\n",
        "f.SetContentFile('X_train_features.npy')\n",
        "f.Upload()\n",
        "\n",
        "f = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": fid}]})\n",
        "f.SetContentFile('X_Val_features.npy')\n",
        "f.Upload()\n",
        "\n",
        "f = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": fid}]})\n",
        "f.SetContentFile('y_train.npy')\n",
        "f.Upload()\n",
        "\n",
        "f = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": fid}]})\n",
        "f.SetContentFile('y_Val.npy')\n",
        "f.Upload()\n",
        "\n",
        "f = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": fid}]})\n",
        "f.SetContentFile('String_labels.npy')\n",
        "f.Upload()\n",
        "\n",
        "f = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": fid}]})\n",
        "f.SetContentFile('X_test_features.npy')\n",
        "f.Upload()\n",
        "\n",
        "f = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": fid}]})\n",
        "f.SetContentFile('img_names.npy')\n",
        "f.Upload()\n",
        "'''\n",
        "f = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": fid}]})\n",
        "f.SetContentFile('augmentedImages5.zip')\n",
        "f.Upload()\n",
        "\n",
        "f = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": fid}]})\n",
        "f.SetContentFile('y_aug.npy')\n",
        "f.Upload()\n",
        "f = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": fid}]})\n",
        "f.SetContentFile('X_aug_features.npy')\n",
        "f.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsweTqz2U4mQ",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow one fully connected layer model with train\n",
        "Test Accuracy 84% (first submission)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNp7S-55Wf6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Load Features and Labels { display-mode: \"code\" }\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "X_train_features = np.load('X_train_features.npy')\n",
        "X_Val_features = np.load('X_Val_features.npy')\n",
        "\n",
        "y_train = np.load('y_train.npy')\n",
        "y_Val = np.load('y_Val.npy')\n",
        "\n",
        "y_train_one_hot = tf.one_hot(y_train,10)\n",
        "y_Val_one_hot = tf.one_hot(y_Val,10)\n",
        "\n",
        "sess = tf.Session()\n",
        "y_train=y_train_one_hot.eval(session=sess)\n",
        "y_val = y_Val_one_hot.eval(session=sess)\n",
        "\n",
        "print(X_train_features.shape)\n",
        "print(y_train.shape)\n",
        "print(X_Val_features.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af8JBpLwVYQJ",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as mt\n",
        "import tensorflow as tf\n",
        "\n",
        "#this function is useful in order to delete old graphs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "height = 8\n",
        "width = 8\n",
        "channels = 1536\n",
        "n_inputs = height*width\n",
        "\n",
        "#parameters of fully connected network and outputs\n",
        "n_fc1 = 1024\n",
        "n_fc2 = 100\n",
        "n_outputs = 10\n",
        "\n",
        "reset_graph()\n",
        "\n",
        "with tf.name_scope(\"inputs\"):\n",
        "    X = tf.placeholder(tf.float32, shape=[None, height,width, channels], name = \"X\")\n",
        "    y = tf.placeholder(tf.int32, shape = [None,n_outputs], name = \"y\")\n",
        "    flat = tf.layers.flatten (X)   \n",
        "\n",
        "with tf.name_scope(\"fc\"):\n",
        "    fc1 = tf.layers.dense(flat, n_fc1, activation = tf.nn.relu, name = \"fc1\")\n",
        "    #fc2 = tf.layers.dense(fc1, n_fc2, activation = tf.nn.relu, name = \"fc2\")\n",
        "\n",
        "with tf.name_scope(\"output\"):\n",
        "    dropout = tf.layers.dropout(fc1,rate=0.2,name=\"dropout\")\n",
        "    logits = tf.layers.dense(dropout, n_outputs, name = \"output\")\n",
        "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
        "\n",
        "with tf.name_scope(\"train\"):\n",
        "    xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=Y_proba, labels=y)\n",
        "    loss = tf.reduce_mean(xentropy)\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=0.000001)\n",
        "    training_op = optimizer.minimize(loss)\n",
        "\n",
        "with tf.name_scope(\"eval\"):\n",
        "    correct =tf.equal(tf.argmax(Y_proba,1),tf.argmax(y,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "with tf.name_scope(\"init_and_save\"):\n",
        "    init = tf.global_variables_initializer()\n",
        "    #saver = tf.train.Saver()\n",
        "\n",
        "n_epochs = 500\n",
        "batch_size = 100\n",
        "num_examples = 2510\n",
        "sess = tf.Session()\n",
        "with sess.as_default():\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(num_examples // batch_size):\n",
        "            X_batch = X_train_features[iteration*batch_size:iteration*batch_size+batch_size,0:]\n",
        "            y_batch = y_train[iteration*batch_size:iteration*batch_size+batch_size,0:]\n",
        "\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_train = accuracy.eval(feed_dict={X: X_train_features, y: y_train})\n",
        "        acc_test = accuracy.eval(feed_dict={X: X_Val_features, y: y_val})\n",
        "        print(\"Epoch:\",epoch+1, \"Train accuracy:\", acc_train, \"test accuracy:\", acc_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBg_lCVoVUZj",
        "colab_type": "text"
      },
      "source": [
        "# Test and submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXEf1BdIVUvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lebels_dictionary={\n",
        "'airport_inside':\t1,\n",
        "'bakery':\t2,\n",
        "'bedroom':\t3,\n",
        "'greenhouse':\t4,\n",
        "'gym':\t5,\n",
        "'kitchen':\t6,\n",
        "'operating_room':\t7,\n",
        "'poolinside':\t8,\n",
        "'restaurant':\t9,\n",
        "'toystore':\t10}\n",
        "\n",
        "#Extracted Features from test data\n",
        "X_test_features = np.load('X_test_features.npy')\n",
        "#classes names ordered in correspondence to the one hot vector used in training phase \n",
        "String_labels = np.load('String_labels.npy')\n",
        "\n",
        "labels_int=np.asarray([lebels_dictionary[i] for i in String_labels])\n",
        "#test images names to be eritten in the csv file\n",
        "img_names = np.load('img_names.npy')\n",
        "\n",
        "\n",
        "X_test_features = np.load('X_test_features.npy')\n",
        "String_labels = np.load('String_labels.npy')\n",
        "img_names = np.load('img_names.npy')\n",
        "\n",
        "feed_dict = {X:X_test_features }\n",
        "classification = sess.run(Y_proba, feed_dict)# output of the softmax layer for the complete test Data\n",
        "predictions_indices =  np.argmax(classification, axis=1)#get index of max probability for all test samples\n",
        "\n",
        "#labels_int the index in it represent the label as the neural network does\n",
        "#           the value  represents the labels as needed in the submission file (same as the announcement)\n",
        "labels_int=np.asarray([lebels_dictionary[i] for i in String_labels])\n",
        "predictions=labels_int[predictions_indices]#conversion between representations \n",
        "\n",
        "DAT =  np.column_stack((np.transpose(img_names),np.transpose(predictions)))\n",
        "np.savetxt('submit.csv',(DAT),delimiter=\",\",header=\"id,label\",  fmt=\"%s\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}